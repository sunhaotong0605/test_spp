{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 300.0,
  "eval_steps": 500,
  "global_step": 195300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.7680491551459293,
      "grad_norm": 0.0408654510974884,
      "learning_rate": 9.969254419677172e-05,
      "loss": 0.4906,
      "step": 500
    },
    {
      "epoch": 1.5360983102918588,
      "grad_norm": 0.132862851023674,
      "learning_rate": 9.930822444273636e-05,
      "loss": 0.369,
      "step": 1000
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 0.03574008122086525,
      "learning_rate": 9.8923904688701e-05,
      "loss": 0.3592,
      "step": 1500
    },
    {
      "epoch": 3.0721966205837172,
      "grad_norm": 0.22133475542068481,
      "learning_rate": 9.853958493466566e-05,
      "loss": 0.3548,
      "step": 2000
    },
    {
      "epoch": 3.8402457757296466,
      "grad_norm": 0.07270719856023788,
      "learning_rate": 9.815526518063029e-05,
      "loss": 0.3526,
      "step": 2500
    },
    {
      "epoch": 4.6082949308755765,
      "grad_norm": 0.21316201984882355,
      "learning_rate": 9.777094542659493e-05,
      "loss": 0.3504,
      "step": 3000
    },
    {
      "epoch": 5.376344086021505,
      "grad_norm": 0.2793440520763397,
      "learning_rate": 9.738662567255957e-05,
      "loss": 0.3495,
      "step": 3500
    },
    {
      "epoch": 6.1443932411674345,
      "grad_norm": 0.5607893466949463,
      "learning_rate": 9.700230591852421e-05,
      "loss": 0.3475,
      "step": 4000
    },
    {
      "epoch": 6.912442396313364,
      "grad_norm": 0.029826661571860313,
      "learning_rate": 9.661798616448886e-05,
      "loss": 0.3454,
      "step": 4500
    },
    {
      "epoch": 7.680491551459293,
      "grad_norm": 0.3797171711921692,
      "learning_rate": 9.623366641045351e-05,
      "loss": 0.3432,
      "step": 5000
    },
    {
      "epoch": 8.448540706605222,
      "grad_norm": 0.09756701439619064,
      "learning_rate": 9.584934665641815e-05,
      "loss": 0.3401,
      "step": 5500
    },
    {
      "epoch": 9.216589861751151,
      "grad_norm": 0.13872946798801422,
      "learning_rate": 9.54650269023828e-05,
      "loss": 0.3362,
      "step": 6000
    },
    {
      "epoch": 9.98463901689708,
      "grad_norm": 0.10804111510515213,
      "learning_rate": 9.508070714834742e-05,
      "loss": 0.3319,
      "step": 6500
    },
    {
      "epoch": 10.75268817204301,
      "grad_norm": 0.23563407361507416,
      "learning_rate": 9.469638739431207e-05,
      "loss": 0.327,
      "step": 7000
    },
    {
      "epoch": 11.52073732718894,
      "grad_norm": 0.06312853842973709,
      "learning_rate": 9.431206764027671e-05,
      "loss": 0.323,
      "step": 7500
    },
    {
      "epoch": 12.288786482334869,
      "grad_norm": 0.2066033035516739,
      "learning_rate": 9.392774788624135e-05,
      "loss": 0.3193,
      "step": 8000
    },
    {
      "epoch": 13.056835637480798,
      "grad_norm": 0.3847476840019226,
      "learning_rate": 9.3543428132206e-05,
      "loss": 0.3165,
      "step": 8500
    },
    {
      "epoch": 13.824884792626728,
      "grad_norm": 0.18194058537483215,
      "learning_rate": 9.315910837817065e-05,
      "loss": 0.314,
      "step": 9000
    },
    {
      "epoch": 14.592933947772657,
      "grad_norm": 0.19905053079128265,
      "learning_rate": 9.277478862413529e-05,
      "loss": 0.312,
      "step": 9500
    },
    {
      "epoch": 15.360983102918587,
      "grad_norm": 0.3790207803249359,
      "learning_rate": 9.239046887009992e-05,
      "loss": 0.3101,
      "step": 10000
    },
    {
      "epoch": 16.129032258064516,
      "grad_norm": 0.5817335247993469,
      "learning_rate": 9.200614911606456e-05,
      "loss": 0.3084,
      "step": 10500
    },
    {
      "epoch": 16.897081413210444,
      "grad_norm": 0.22757165133953094,
      "learning_rate": 9.16218293620292e-05,
      "loss": 0.3064,
      "step": 11000
    },
    {
      "epoch": 17.665130568356375,
      "grad_norm": 0.17696283757686615,
      "learning_rate": 9.123750960799386e-05,
      "loss": 0.3056,
      "step": 11500
    },
    {
      "epoch": 18.433179723502302,
      "grad_norm": 0.10806941986083984,
      "learning_rate": 9.08531898539585e-05,
      "loss": 0.3042,
      "step": 12000
    },
    {
      "epoch": 19.201228878648234,
      "grad_norm": 0.10446509718894958,
      "learning_rate": 9.046887009992314e-05,
      "loss": 0.3022,
      "step": 12500
    },
    {
      "epoch": 19.96927803379416,
      "grad_norm": 0.3500995635986328,
      "learning_rate": 9.008455034588779e-05,
      "loss": 0.3017,
      "step": 13000
    },
    {
      "epoch": 20.737327188940093,
      "grad_norm": 0.2518332600593567,
      "learning_rate": 8.970023059185243e-05,
      "loss": 0.3009,
      "step": 13500
    },
    {
      "epoch": 21.50537634408602,
      "grad_norm": 0.3970208168029785,
      "learning_rate": 8.931591083781706e-05,
      "loss": 0.2999,
      "step": 14000
    },
    {
      "epoch": 22.27342549923195,
      "grad_norm": 0.3066309690475464,
      "learning_rate": 8.893159108378171e-05,
      "loss": 0.2989,
      "step": 14500
    },
    {
      "epoch": 23.04147465437788,
      "grad_norm": 0.25718560814857483,
      "learning_rate": 8.854727132974635e-05,
      "loss": 0.2976,
      "step": 15000
    },
    {
      "epoch": 23.80952380952381,
      "grad_norm": 0.192782461643219,
      "learning_rate": 8.8162951575711e-05,
      "loss": 0.2969,
      "step": 15500
    },
    {
      "epoch": 24.577572964669738,
      "grad_norm": 0.17776238918304443,
      "learning_rate": 8.777863182167564e-05,
      "loss": 0.2961,
      "step": 16000
    },
    {
      "epoch": 25.34562211981567,
      "grad_norm": 0.31700655817985535,
      "learning_rate": 8.739431206764028e-05,
      "loss": 0.2951,
      "step": 16500
    },
    {
      "epoch": 26.113671274961597,
      "grad_norm": 0.5608062148094177,
      "learning_rate": 8.700999231360492e-05,
      "loss": 0.2937,
      "step": 17000
    },
    {
      "epoch": 26.881720430107528,
      "grad_norm": 0.15439574420452118,
      "learning_rate": 8.662567255956957e-05,
      "loss": 0.2923,
      "step": 17500
    },
    {
      "epoch": 27.649769585253456,
      "grad_norm": 0.6274396777153015,
      "learning_rate": 8.624135280553421e-05,
      "loss": 0.291,
      "step": 18000
    },
    {
      "epoch": 28.417818740399387,
      "grad_norm": 0.6236559748649597,
      "learning_rate": 8.585703305149885e-05,
      "loss": 0.2894,
      "step": 18500
    },
    {
      "epoch": 29.185867895545314,
      "grad_norm": 0.29232457280158997,
      "learning_rate": 8.547271329746349e-05,
      "loss": 0.2873,
      "step": 19000
    },
    {
      "epoch": 29.953917050691246,
      "grad_norm": 0.4280603528022766,
      "learning_rate": 8.508839354342813e-05,
      "loss": 0.2856,
      "step": 19500
    },
    {
      "epoch": 30.721966205837173,
      "grad_norm": 0.3690420687198639,
      "learning_rate": 8.470407378939278e-05,
      "loss": 0.2831,
      "step": 20000
    },
    {
      "epoch": 31.490015360983104,
      "grad_norm": 0.16991567611694336,
      "learning_rate": 8.431975403535742e-05,
      "loss": 0.2805,
      "step": 20500
    },
    {
      "epoch": 32.25806451612903,
      "grad_norm": 0.4924118220806122,
      "learning_rate": 8.393543428132207e-05,
      "loss": 0.2792,
      "step": 21000
    },
    {
      "epoch": 33.02611367127496,
      "grad_norm": 0.41352954506874084,
      "learning_rate": 8.355111452728672e-05,
      "loss": 0.277,
      "step": 21500
    },
    {
      "epoch": 33.794162826420894,
      "grad_norm": 0.2943051755428314,
      "learning_rate": 8.316679477325134e-05,
      "loss": 0.2756,
      "step": 22000
    },
    {
      "epoch": 34.56221198156682,
      "grad_norm": 0.2635045349597931,
      "learning_rate": 8.278247501921599e-05,
      "loss": 0.2745,
      "step": 22500
    },
    {
      "epoch": 35.33026113671275,
      "grad_norm": 0.4375761151313782,
      "learning_rate": 8.239815526518063e-05,
      "loss": 0.2732,
      "step": 23000
    },
    {
      "epoch": 36.09831029185868,
      "grad_norm": 0.3745785653591156,
      "learning_rate": 8.201383551114527e-05,
      "loss": 0.2723,
      "step": 23500
    },
    {
      "epoch": 36.866359447004605,
      "grad_norm": 0.40662264823913574,
      "learning_rate": 8.162951575710993e-05,
      "loss": 0.271,
      "step": 24000
    },
    {
      "epoch": 37.634408602150536,
      "grad_norm": 0.16016961634159088,
      "learning_rate": 8.124519600307457e-05,
      "loss": 0.2702,
      "step": 24500
    },
    {
      "epoch": 38.40245775729647,
      "grad_norm": 0.5205707550048828,
      "learning_rate": 8.086087624903921e-05,
      "loss": 0.2699,
      "step": 25000
    },
    {
      "epoch": 39.1705069124424,
      "grad_norm": 0.46905994415283203,
      "learning_rate": 8.047655649500385e-05,
      "loss": 0.2682,
      "step": 25500
    },
    {
      "epoch": 39.93855606758832,
      "grad_norm": 0.396037757396698,
      "learning_rate": 8.009223674096848e-05,
      "loss": 0.2679,
      "step": 26000
    },
    {
      "epoch": 40.706605222734254,
      "grad_norm": 0.21553511917591095,
      "learning_rate": 7.970791698693312e-05,
      "loss": 0.2673,
      "step": 26500
    },
    {
      "epoch": 41.474654377880185,
      "grad_norm": 0.2127918004989624,
      "learning_rate": 7.932359723289778e-05,
      "loss": 0.2665,
      "step": 27000
    },
    {
      "epoch": 42.242703533026116,
      "grad_norm": 0.4304572343826294,
      "learning_rate": 7.893927747886242e-05,
      "loss": 0.2658,
      "step": 27500
    },
    {
      "epoch": 43.01075268817204,
      "grad_norm": 0.4319040775299072,
      "learning_rate": 7.855495772482706e-05,
      "loss": 0.2651,
      "step": 28000
    },
    {
      "epoch": 43.77880184331797,
      "grad_norm": 0.22034382820129395,
      "learning_rate": 7.81706379707917e-05,
      "loss": 0.2646,
      "step": 28500
    },
    {
      "epoch": 44.5468509984639,
      "grad_norm": 0.5386462807655334,
      "learning_rate": 7.778631821675635e-05,
      "loss": 0.2638,
      "step": 29000
    },
    {
      "epoch": 45.314900153609834,
      "grad_norm": 0.4061708152294159,
      "learning_rate": 7.740199846272099e-05,
      "loss": 0.2639,
      "step": 29500
    },
    {
      "epoch": 46.08294930875576,
      "grad_norm": 0.19021016359329224,
      "learning_rate": 7.701767870868562e-05,
      "loss": 0.2626,
      "step": 30000
    },
    {
      "epoch": 46.85099846390169,
      "grad_norm": 0.4255306124687195,
      "learning_rate": 7.663335895465027e-05,
      "loss": 0.2623,
      "step": 30500
    },
    {
      "epoch": 47.61904761904762,
      "grad_norm": 0.32219138741493225,
      "learning_rate": 7.624903920061492e-05,
      "loss": 0.2619,
      "step": 31000
    },
    {
      "epoch": 48.38709677419355,
      "grad_norm": 0.35790595412254333,
      "learning_rate": 7.586471944657956e-05,
      "loss": 0.2612,
      "step": 31500
    },
    {
      "epoch": 49.155145929339476,
      "grad_norm": 0.30970498919487,
      "learning_rate": 7.54803996925442e-05,
      "loss": 0.2607,
      "step": 32000
    },
    {
      "epoch": 49.92319508448541,
      "grad_norm": 0.1506965458393097,
      "learning_rate": 7.509607993850884e-05,
      "loss": 0.2604,
      "step": 32500
    },
    {
      "epoch": 50.69124423963134,
      "grad_norm": 0.2410007268190384,
      "learning_rate": 7.471176018447349e-05,
      "loss": 0.26,
      "step": 33000
    },
    {
      "epoch": 51.45929339477726,
      "grad_norm": 0.4350080192089081,
      "learning_rate": 7.432744043043813e-05,
      "loss": 0.2594,
      "step": 33500
    },
    {
      "epoch": 52.22734254992319,
      "grad_norm": 0.5608216524124146,
      "learning_rate": 7.394312067640277e-05,
      "loss": 0.2587,
      "step": 34000
    },
    {
      "epoch": 52.995391705069125,
      "grad_norm": 0.2582431137561798,
      "learning_rate": 7.355880092236741e-05,
      "loss": 0.2586,
      "step": 34500
    },
    {
      "epoch": 53.763440860215056,
      "grad_norm": 0.36212584376335144,
      "learning_rate": 7.317448116833205e-05,
      "loss": 0.258,
      "step": 35000
    },
    {
      "epoch": 54.53149001536098,
      "grad_norm": 0.44000276923179626,
      "learning_rate": 7.27901614142967e-05,
      "loss": 0.2578,
      "step": 35500
    },
    {
      "epoch": 55.29953917050691,
      "grad_norm": 0.32600194215774536,
      "learning_rate": 7.240584166026134e-05,
      "loss": 0.2571,
      "step": 36000
    },
    {
      "epoch": 56.06758832565284,
      "grad_norm": 0.3756263256072998,
      "learning_rate": 7.202152190622598e-05,
      "loss": 0.257,
      "step": 36500
    },
    {
      "epoch": 56.83563748079877,
      "grad_norm": 0.6823757886886597,
      "learning_rate": 7.163720215219064e-05,
      "loss": 0.2564,
      "step": 37000
    },
    {
      "epoch": 57.6036866359447,
      "grad_norm": 0.21802009642124176,
      "learning_rate": 7.125288239815528e-05,
      "loss": 0.2563,
      "step": 37500
    },
    {
      "epoch": 58.37173579109063,
      "grad_norm": 0.604970395565033,
      "learning_rate": 7.08685626441199e-05,
      "loss": 0.2558,
      "step": 38000
    },
    {
      "epoch": 59.13978494623656,
      "grad_norm": 0.41365188360214233,
      "learning_rate": 7.048424289008455e-05,
      "loss": 0.2553,
      "step": 38500
    },
    {
      "epoch": 59.90783410138249,
      "grad_norm": 0.3509350121021271,
      "learning_rate": 7.009992313604919e-05,
      "loss": 0.2549,
      "step": 39000
    },
    {
      "epoch": 60.675883256528415,
      "grad_norm": 0.18576279282569885,
      "learning_rate": 6.971560338201383e-05,
      "loss": 0.2544,
      "step": 39500
    },
    {
      "epoch": 61.443932411674346,
      "grad_norm": 0.2838064730167389,
      "learning_rate": 6.933128362797849e-05,
      "loss": 0.2543,
      "step": 40000
    },
    {
      "epoch": 62.21198156682028,
      "grad_norm": 0.4591539204120636,
      "learning_rate": 6.894696387394313e-05,
      "loss": 0.2534,
      "step": 40500
    },
    {
      "epoch": 62.98003072196621,
      "grad_norm": 0.46652451157569885,
      "learning_rate": 6.856264411990777e-05,
      "loss": 0.2535,
      "step": 41000
    },
    {
      "epoch": 63.74807987711213,
      "grad_norm": 0.3380849063396454,
      "learning_rate": 6.81783243658724e-05,
      "loss": 0.2531,
      "step": 41500
    },
    {
      "epoch": 64.51612903225806,
      "grad_norm": 0.39784324169158936,
      "learning_rate": 6.779400461183704e-05,
      "loss": 0.2528,
      "step": 42000
    },
    {
      "epoch": 65.284178187404,
      "grad_norm": 0.37584397196769714,
      "learning_rate": 6.740968485780169e-05,
      "loss": 0.2519,
      "step": 42500
    },
    {
      "epoch": 66.05222734254993,
      "grad_norm": 0.3090702295303345,
      "learning_rate": 6.702536510376634e-05,
      "loss": 0.2519,
      "step": 43000
    },
    {
      "epoch": 66.82027649769586,
      "grad_norm": 0.31293922662734985,
      "learning_rate": 6.664104534973098e-05,
      "loss": 0.2514,
      "step": 43500
    },
    {
      "epoch": 67.58832565284179,
      "grad_norm": 0.2577996253967285,
      "learning_rate": 6.625672559569563e-05,
      "loss": 0.251,
      "step": 44000
    },
    {
      "epoch": 68.3563748079877,
      "grad_norm": 0.2952365577220917,
      "learning_rate": 6.587240584166027e-05,
      "loss": 0.2506,
      "step": 44500
    },
    {
      "epoch": 69.12442396313364,
      "grad_norm": 0.8615024089813232,
      "learning_rate": 6.548808608762491e-05,
      "loss": 0.2503,
      "step": 45000
    },
    {
      "epoch": 69.89247311827957,
      "grad_norm": 0.4665962755680084,
      "learning_rate": 6.510376633358954e-05,
      "loss": 0.2498,
      "step": 45500
    },
    {
      "epoch": 70.6605222734255,
      "grad_norm": 0.4179069697856903,
      "learning_rate": 6.47194465795542e-05,
      "loss": 0.2497,
      "step": 46000
    },
    {
      "epoch": 71.42857142857143,
      "grad_norm": 0.20619083940982819,
      "learning_rate": 6.433512682551884e-05,
      "loss": 0.2485,
      "step": 46500
    },
    {
      "epoch": 72.19662058371736,
      "grad_norm": 0.3004632592201233,
      "learning_rate": 6.395080707148348e-05,
      "loss": 0.2489,
      "step": 47000
    },
    {
      "epoch": 72.9646697388633,
      "grad_norm": 0.32019421458244324,
      "learning_rate": 6.356648731744812e-05,
      "loss": 0.2483,
      "step": 47500
    },
    {
      "epoch": 73.73271889400921,
      "grad_norm": 0.3468583822250366,
      "learning_rate": 6.318216756341276e-05,
      "loss": 0.2479,
      "step": 48000
    },
    {
      "epoch": 74.50076804915514,
      "grad_norm": 0.45211008191108704,
      "learning_rate": 6.27978478093774e-05,
      "loss": 0.2474,
      "step": 48500
    },
    {
      "epoch": 75.26881720430107,
      "grad_norm": 0.5212024450302124,
      "learning_rate": 6.241352805534205e-05,
      "loss": 0.2473,
      "step": 49000
    },
    {
      "epoch": 76.036866359447,
      "grad_norm": 0.5583730936050415,
      "learning_rate": 6.202920830130669e-05,
      "loss": 0.2467,
      "step": 49500
    },
    {
      "epoch": 76.80491551459293,
      "grad_norm": 0.3141597807407379,
      "learning_rate": 6.164488854727133e-05,
      "loss": 0.2467,
      "step": 50000
    },
    {
      "epoch": 77.57296466973887,
      "grad_norm": 0.5097950100898743,
      "learning_rate": 6.126056879323597e-05,
      "loss": 0.2458,
      "step": 50500
    },
    {
      "epoch": 78.3410138248848,
      "grad_norm": 0.6621116399765015,
      "learning_rate": 6.0876249039200616e-05,
      "loss": 0.2453,
      "step": 51000
    },
    {
      "epoch": 79.10906298003073,
      "grad_norm": 0.18492090702056885,
      "learning_rate": 6.049192928516526e-05,
      "loss": 0.2453,
      "step": 51500
    },
    {
      "epoch": 79.87711213517665,
      "grad_norm": 0.5600413680076599,
      "learning_rate": 6.010760953112991e-05,
      "loss": 0.245,
      "step": 52000
    },
    {
      "epoch": 80.64516129032258,
      "grad_norm": 0.3517235517501831,
      "learning_rate": 5.972328977709455e-05,
      "loss": 0.2445,
      "step": 52500
    },
    {
      "epoch": 81.41321044546851,
      "grad_norm": 0.3831762969493866,
      "learning_rate": 5.933897002305919e-05,
      "loss": 0.2443,
      "step": 53000
    },
    {
      "epoch": 82.18125960061444,
      "grad_norm": 0.44536200165748596,
      "learning_rate": 5.895465026902383e-05,
      "loss": 0.2438,
      "step": 53500
    },
    {
      "epoch": 82.94930875576037,
      "grad_norm": 0.402950257062912,
      "learning_rate": 5.857033051498847e-05,
      "loss": 0.2435,
      "step": 54000
    },
    {
      "epoch": 83.7173579109063,
      "grad_norm": 0.25896400213241577,
      "learning_rate": 5.818601076095311e-05,
      "loss": 0.2432,
      "step": 54500
    },
    {
      "epoch": 84.48540706605223,
      "grad_norm": 0.42709505558013916,
      "learning_rate": 5.780169100691776e-05,
      "loss": 0.2428,
      "step": 55000
    },
    {
      "epoch": 85.25345622119816,
      "grad_norm": 0.5280964970588684,
      "learning_rate": 5.74173712528824e-05,
      "loss": 0.2427,
      "step": 55500
    },
    {
      "epoch": 86.02150537634408,
      "grad_norm": 0.46402841806411743,
      "learning_rate": 5.7033051498847044e-05,
      "loss": 0.2421,
      "step": 56000
    },
    {
      "epoch": 86.78955453149001,
      "grad_norm": 0.4011191427707672,
      "learning_rate": 5.6648731744811686e-05,
      "loss": 0.2418,
      "step": 56500
    },
    {
      "epoch": 87.55760368663594,
      "grad_norm": 0.5410071015357971,
      "learning_rate": 5.6264411990776335e-05,
      "loss": 0.2417,
      "step": 57000
    },
    {
      "epoch": 88.32565284178187,
      "grad_norm": 0.1263425350189209,
      "learning_rate": 5.5880092236740964e-05,
      "loss": 0.2416,
      "step": 57500
    },
    {
      "epoch": 89.0937019969278,
      "grad_norm": 0.3433493375778198,
      "learning_rate": 5.549577248270561e-05,
      "loss": 0.241,
      "step": 58000
    },
    {
      "epoch": 89.86175115207374,
      "grad_norm": 0.4023488461971283,
      "learning_rate": 5.5111452728670255e-05,
      "loss": 0.2408,
      "step": 58500
    },
    {
      "epoch": 90.62980030721967,
      "grad_norm": 0.3814984858036041,
      "learning_rate": 5.47271329746349e-05,
      "loss": 0.2404,
      "step": 59000
    },
    {
      "epoch": 91.39784946236558,
      "grad_norm": 0.5151283740997314,
      "learning_rate": 5.434281322059954e-05,
      "loss": 0.2403,
      "step": 59500
    },
    {
      "epoch": 92.16589861751152,
      "grad_norm": 0.494351863861084,
      "learning_rate": 5.395849346656419e-05,
      "loss": 0.2398,
      "step": 60000
    },
    {
      "epoch": 92.93394777265745,
      "grad_norm": 0.46551740169525146,
      "learning_rate": 5.357417371252883e-05,
      "loss": 0.2396,
      "step": 60500
    },
    {
      "epoch": 93.70199692780338,
      "grad_norm": 0.224564790725708,
      "learning_rate": 5.318985395849347e-05,
      "loss": 0.2391,
      "step": 61000
    },
    {
      "epoch": 94.47004608294931,
      "grad_norm": 0.2181292623281479,
      "learning_rate": 5.280553420445811e-05,
      "loss": 0.2392,
      "step": 61500
    },
    {
      "epoch": 95.23809523809524,
      "grad_norm": 0.3135073184967041,
      "learning_rate": 5.242121445042275e-05,
      "loss": 0.239,
      "step": 62000
    },
    {
      "epoch": 96.00614439324117,
      "grad_norm": 0.11225894838571548,
      "learning_rate": 5.203689469638739e-05,
      "loss": 0.2388,
      "step": 62500
    },
    {
      "epoch": 96.7741935483871,
      "grad_norm": 0.35731562972068787,
      "learning_rate": 5.165257494235204e-05,
      "loss": 0.2384,
      "step": 63000
    },
    {
      "epoch": 97.54224270353302,
      "grad_norm": 0.3745666742324829,
      "learning_rate": 5.126825518831668e-05,
      "loss": 0.2382,
      "step": 63500
    },
    {
      "epoch": 98.31029185867895,
      "grad_norm": 0.41770368814468384,
      "learning_rate": 5.0883935434281325e-05,
      "loss": 0.2376,
      "step": 64000
    },
    {
      "epoch": 99.07834101382488,
      "grad_norm": 0.322075754404068,
      "learning_rate": 5.049961568024597e-05,
      "loss": 0.2378,
      "step": 64500
    },
    {
      "epoch": 99.84639016897081,
      "grad_norm": 0.4496680498123169,
      "learning_rate": 5.0115295926210617e-05,
      "loss": 0.2375,
      "step": 65000
    },
    {
      "epoch": 100.61443932411674,
      "grad_norm": 0.2755807638168335,
      "learning_rate": 4.973097617217525e-05,
      "loss": 0.2373,
      "step": 65500
    },
    {
      "epoch": 101.38248847926268,
      "grad_norm": 0.2982703745365143,
      "learning_rate": 4.9346656418139894e-05,
      "loss": 0.2372,
      "step": 66000
    },
    {
      "epoch": 102.15053763440861,
      "grad_norm": 0.2799263000488281,
      "learning_rate": 4.8962336664104536e-05,
      "loss": 0.2367,
      "step": 66500
    },
    {
      "epoch": 102.91858678955452,
      "grad_norm": 0.5088260173797607,
      "learning_rate": 4.857801691006918e-05,
      "loss": 0.2363,
      "step": 67000
    },
    {
      "epoch": 103.68663594470046,
      "grad_norm": 0.1940484493970871,
      "learning_rate": 4.819369715603382e-05,
      "loss": 0.2364,
      "step": 67500
    },
    {
      "epoch": 104.45468509984639,
      "grad_norm": 0.43685922026634216,
      "learning_rate": 4.780937740199847e-05,
      "loss": 0.236,
      "step": 68000
    },
    {
      "epoch": 105.22273425499232,
      "grad_norm": 0.2687305510044098,
      "learning_rate": 4.7425057647963105e-05,
      "loss": 0.236,
      "step": 68500
    },
    {
      "epoch": 105.99078341013825,
      "grad_norm": 0.3499176502227783,
      "learning_rate": 4.704073789392775e-05,
      "loss": 0.2357,
      "step": 69000
    },
    {
      "epoch": 106.75883256528418,
      "grad_norm": 0.3544580638408661,
      "learning_rate": 4.6656418139892396e-05,
      "loss": 0.2357,
      "step": 69500
    },
    {
      "epoch": 107.52688172043011,
      "grad_norm": 0.27384164929389954,
      "learning_rate": 4.627209838585704e-05,
      "loss": 0.2353,
      "step": 70000
    },
    {
      "epoch": 108.29493087557604,
      "grad_norm": 0.3492863178253174,
      "learning_rate": 4.588777863182167e-05,
      "loss": 0.235,
      "step": 70500
    },
    {
      "epoch": 109.06298003072196,
      "grad_norm": 0.5616992712020874,
      "learning_rate": 4.550345887778632e-05,
      "loss": 0.2348,
      "step": 71000
    },
    {
      "epoch": 109.83102918586789,
      "grad_norm": 0.2647263705730438,
      "learning_rate": 4.5119139123750964e-05,
      "loss": 0.2346,
      "step": 71500
    },
    {
      "epoch": 110.59907834101382,
      "grad_norm": 0.2418813854455948,
      "learning_rate": 4.4734819369715607e-05,
      "loss": 0.2348,
      "step": 72000
    },
    {
      "epoch": 111.36712749615975,
      "grad_norm": 0.23704048991203308,
      "learning_rate": 4.435049961568025e-05,
      "loss": 0.2344,
      "step": 72500
    },
    {
      "epoch": 112.13517665130568,
      "grad_norm": 0.3397287428379059,
      "learning_rate": 4.396617986164489e-05,
      "loss": 0.234,
      "step": 73000
    },
    {
      "epoch": 112.90322580645162,
      "grad_norm": 0.9866966605186462,
      "learning_rate": 4.358186010760953e-05,
      "loss": 0.2342,
      "step": 73500
    },
    {
      "epoch": 113.67127496159755,
      "grad_norm": 0.5057801008224487,
      "learning_rate": 4.3197540353574175e-05,
      "loss": 0.2341,
      "step": 74000
    },
    {
      "epoch": 114.43932411674348,
      "grad_norm": 0.4133657217025757,
      "learning_rate": 4.281322059953882e-05,
      "loss": 0.2334,
      "step": 74500
    },
    {
      "epoch": 115.2073732718894,
      "grad_norm": 0.2317778617143631,
      "learning_rate": 4.242890084550346e-05,
      "loss": 0.2334,
      "step": 75000
    },
    {
      "epoch": 115.97542242703533,
      "grad_norm": 0.37019702792167664,
      "learning_rate": 4.20445810914681e-05,
      "loss": 0.2334,
      "step": 75500
    },
    {
      "epoch": 116.74347158218126,
      "grad_norm": 0.27264732122421265,
      "learning_rate": 4.1660261337432744e-05,
      "loss": 0.2331,
      "step": 76000
    },
    {
      "epoch": 117.51152073732719,
      "grad_norm": 0.4368603229522705,
      "learning_rate": 4.1275941583397386e-05,
      "loss": 0.2331,
      "step": 76500
    },
    {
      "epoch": 118.27956989247312,
      "grad_norm": 0.2903188169002533,
      "learning_rate": 4.089162182936203e-05,
      "loss": 0.2328,
      "step": 77000
    },
    {
      "epoch": 119.04761904761905,
      "grad_norm": 0.24510475993156433,
      "learning_rate": 4.050730207532668e-05,
      "loss": 0.233,
      "step": 77500
    },
    {
      "epoch": 119.81566820276498,
      "grad_norm": 0.3750932216644287,
      "learning_rate": 4.012298232129131e-05,
      "loss": 0.2325,
      "step": 78000
    },
    {
      "epoch": 120.5837173579109,
      "grad_norm": 0.8545600771903992,
      "learning_rate": 3.9738662567255955e-05,
      "loss": 0.2318,
      "step": 78500
    },
    {
      "epoch": 121.35176651305683,
      "grad_norm": 0.46600550413131714,
      "learning_rate": 3.9354342813220603e-05,
      "loss": 0.2328,
      "step": 79000
    },
    {
      "epoch": 122.11981566820276,
      "grad_norm": 0.285397469997406,
      "learning_rate": 3.8970023059185246e-05,
      "loss": 0.2318,
      "step": 79500
    },
    {
      "epoch": 122.88786482334869,
      "grad_norm": 0.2876977324485779,
      "learning_rate": 3.858570330514988e-05,
      "loss": 0.232,
      "step": 80000
    },
    {
      "epoch": 123.65591397849462,
      "grad_norm": 0.40373414754867554,
      "learning_rate": 3.820138355111453e-05,
      "loss": 0.2318,
      "step": 80500
    },
    {
      "epoch": 124.42396313364056,
      "grad_norm": 0.5933991074562073,
      "learning_rate": 3.781706379707917e-05,
      "loss": 0.2317,
      "step": 81000
    },
    {
      "epoch": 125.19201228878649,
      "grad_norm": 0.48667284846305847,
      "learning_rate": 3.7432744043043814e-05,
      "loss": 0.2315,
      "step": 81500
    },
    {
      "epoch": 125.96006144393242,
      "grad_norm": 0.2961026728153229,
      "learning_rate": 3.7048424289008456e-05,
      "loss": 0.2315,
      "step": 82000
    },
    {
      "epoch": 126.72811059907833,
      "grad_norm": 0.343494176864624,
      "learning_rate": 3.66641045349731e-05,
      "loss": 0.231,
      "step": 82500
    },
    {
      "epoch": 127.49615975422427,
      "grad_norm": 0.39949411153793335,
      "learning_rate": 3.627978478093774e-05,
      "loss": 0.2312,
      "step": 83000
    },
    {
      "epoch": 128.2642089093702,
      "grad_norm": 0.5287556052207947,
      "learning_rate": 3.589546502690239e-05,
      "loss": 0.2311,
      "step": 83500
    },
    {
      "epoch": 129.03225806451613,
      "grad_norm": 0.5709948539733887,
      "learning_rate": 3.5511145272867025e-05,
      "loss": 0.2307,
      "step": 84000
    },
    {
      "epoch": 129.80030721966205,
      "grad_norm": 0.24385203421115875,
      "learning_rate": 3.512682551883167e-05,
      "loss": 0.2306,
      "step": 84500
    },
    {
      "epoch": 130.568356374808,
      "grad_norm": 0.33599671721458435,
      "learning_rate": 3.474250576479631e-05,
      "loss": 0.2305,
      "step": 85000
    },
    {
      "epoch": 131.3364055299539,
      "grad_norm": 0.32864636182785034,
      "learning_rate": 3.435818601076096e-05,
      "loss": 0.2304,
      "step": 85500
    },
    {
      "epoch": 132.10445468509985,
      "grad_norm": 0.3872312605381012,
      "learning_rate": 3.3973866256725594e-05,
      "loss": 0.2303,
      "step": 86000
    },
    {
      "epoch": 132.87250384024577,
      "grad_norm": 0.31826531887054443,
      "learning_rate": 3.3589546502690236e-05,
      "loss": 0.2302,
      "step": 86500
    },
    {
      "epoch": 133.64055299539172,
      "grad_norm": 0.6353813409805298,
      "learning_rate": 3.3205226748654885e-05,
      "loss": 0.23,
      "step": 87000
    },
    {
      "epoch": 134.40860215053763,
      "grad_norm": 0.4007168114185333,
      "learning_rate": 3.282090699461953e-05,
      "loss": 0.2298,
      "step": 87500
    },
    {
      "epoch": 135.17665130568358,
      "grad_norm": 0.28506848216056824,
      "learning_rate": 3.243658724058416e-05,
      "loss": 0.2298,
      "step": 88000
    },
    {
      "epoch": 135.9447004608295,
      "grad_norm": 0.46424952149391174,
      "learning_rate": 3.205226748654881e-05,
      "loss": 0.2296,
      "step": 88500
    },
    {
      "epoch": 136.7127496159754,
      "grad_norm": 0.29887494444847107,
      "learning_rate": 3.166794773251345e-05,
      "loss": 0.2293,
      "step": 89000
    },
    {
      "epoch": 137.48079877112136,
      "grad_norm": 0.38110077381134033,
      "learning_rate": 3.1283627978478095e-05,
      "loss": 0.2295,
      "step": 89500
    },
    {
      "epoch": 138.24884792626727,
      "grad_norm": 0.4309717118740082,
      "learning_rate": 3.089930822444274e-05,
      "loss": 0.2295,
      "step": 90000
    },
    {
      "epoch": 139.01689708141322,
      "grad_norm": 0.36387258768081665,
      "learning_rate": 3.051498847040738e-05,
      "loss": 0.2289,
      "step": 90500
    },
    {
      "epoch": 139.78494623655914,
      "grad_norm": 0.2881489396095276,
      "learning_rate": 3.0130668716372025e-05,
      "loss": 0.229,
      "step": 91000
    },
    {
      "epoch": 140.55299539170508,
      "grad_norm": 0.4294946491718292,
      "learning_rate": 2.9746348962336667e-05,
      "loss": 0.2285,
      "step": 91500
    },
    {
      "epoch": 141.321044546851,
      "grad_norm": 0.20262742042541504,
      "learning_rate": 2.9362029208301306e-05,
      "loss": 0.2292,
      "step": 92000
    },
    {
      "epoch": 142.08909370199692,
      "grad_norm": 0.2880605459213257,
      "learning_rate": 2.897770945426595e-05,
      "loss": 0.2286,
      "step": 92500
    },
    {
      "epoch": 142.85714285714286,
      "grad_norm": 0.25148001313209534,
      "learning_rate": 2.8593389700230594e-05,
      "loss": 0.2284,
      "step": 93000
    },
    {
      "epoch": 143.62519201228878,
      "grad_norm": 0.44772735238075256,
      "learning_rate": 2.820906994619524e-05,
      "loss": 0.2288,
      "step": 93500
    },
    {
      "epoch": 144.39324116743472,
      "grad_norm": 0.2279478758573532,
      "learning_rate": 2.7824750192159875e-05,
      "loss": 0.2277,
      "step": 94000
    },
    {
      "epoch": 145.16129032258064,
      "grad_norm": 0.4115956425666809,
      "learning_rate": 2.744043043812452e-05,
      "loss": 0.2285,
      "step": 94500
    },
    {
      "epoch": 145.9293394777266,
      "grad_norm": 0.32090386748313904,
      "learning_rate": 2.7056110684089166e-05,
      "loss": 0.2281,
      "step": 95000
    },
    {
      "epoch": 146.6973886328725,
      "grad_norm": 0.38981983065605164,
      "learning_rate": 2.6671790930053808e-05,
      "loss": 0.2278,
      "step": 95500
    },
    {
      "epoch": 147.46543778801842,
      "grad_norm": 0.22809800505638123,
      "learning_rate": 2.6287471176018447e-05,
      "loss": 0.228,
      "step": 96000
    },
    {
      "epoch": 148.23348694316437,
      "grad_norm": 0.2946784794330597,
      "learning_rate": 2.5903151421983092e-05,
      "loss": 0.2279,
      "step": 96500
    },
    {
      "epoch": 149.00153609831028,
      "grad_norm": 0.5927323698997498,
      "learning_rate": 2.5518831667947734e-05,
      "loss": 0.2275,
      "step": 97000
    },
    {
      "epoch": 149.76958525345623,
      "grad_norm": 0.4569791257381439,
      "learning_rate": 2.513451191391238e-05,
      "loss": 0.2277,
      "step": 97500
    },
    {
      "epoch": 150.53763440860214,
      "grad_norm": 0.30372849106788635,
      "learning_rate": 2.475019215987702e-05,
      "loss": 0.2273,
      "step": 98000
    },
    {
      "epoch": 151.3056835637481,
      "grad_norm": 0.3717575967311859,
      "learning_rate": 2.436587240584166e-05,
      "loss": 0.2275,
      "step": 98500
    },
    {
      "epoch": 152.073732718894,
      "grad_norm": 0.4527151882648468,
      "learning_rate": 2.3981552651806306e-05,
      "loss": 0.2272,
      "step": 99000
    },
    {
      "epoch": 152.84178187403995,
      "grad_norm": 0.34466353058815,
      "learning_rate": 2.3597232897770945e-05,
      "loss": 0.2272,
      "step": 99500
    },
    {
      "epoch": 153.60983102918587,
      "grad_norm": 0.3712652921676636,
      "learning_rate": 2.321291314373559e-05,
      "loss": 0.2271,
      "step": 100000
    },
    {
      "epoch": 154.3778801843318,
      "grad_norm": 0.29103952646255493,
      "learning_rate": 2.2828593389700233e-05,
      "loss": 0.2267,
      "step": 100500
    },
    {
      "epoch": 155.14592933947773,
      "grad_norm": 0.33606231212615967,
      "learning_rate": 2.2444273635664875e-05,
      "loss": 0.2271,
      "step": 101000
    },
    {
      "epoch": 155.91397849462365,
      "grad_norm": 0.35047197341918945,
      "learning_rate": 2.2059953881629517e-05,
      "loss": 0.2267,
      "step": 101500
    },
    {
      "epoch": 156.6820276497696,
      "grad_norm": 0.5592762231826782,
      "learning_rate": 2.167563412759416e-05,
      "loss": 0.2271,
      "step": 102000
    },
    {
      "epoch": 157.4500768049155,
      "grad_norm": 0.31587934494018555,
      "learning_rate": 2.12913143735588e-05,
      "loss": 0.2265,
      "step": 102500
    },
    {
      "epoch": 158.21812596006146,
      "grad_norm": 0.2456059455871582,
      "learning_rate": 2.0906994619523447e-05,
      "loss": 0.2264,
      "step": 103000
    },
    {
      "epoch": 158.98617511520737,
      "grad_norm": 0.2951551675796509,
      "learning_rate": 2.0522674865488086e-05,
      "loss": 0.2267,
      "step": 103500
    },
    {
      "epoch": 159.7542242703533,
      "grad_norm": 0.25505536794662476,
      "learning_rate": 2.013835511145273e-05,
      "loss": 0.2262,
      "step": 104000
    },
    {
      "epoch": 160.52227342549924,
      "grad_norm": 0.26028767228126526,
      "learning_rate": 1.9754035357417373e-05,
      "loss": 0.2264,
      "step": 104500
    },
    {
      "epoch": 161.29032258064515,
      "grad_norm": 0.35848841071128845,
      "learning_rate": 1.9369715603382015e-05,
      "loss": 0.2267,
      "step": 105000
    },
    {
      "epoch": 162.0583717357911,
      "grad_norm": 0.4267805814743042,
      "learning_rate": 1.8985395849346658e-05,
      "loss": 0.2259,
      "step": 105500
    },
    {
      "epoch": 162.82642089093702,
      "grad_norm": 0.45313918590545654,
      "learning_rate": 1.86010760953113e-05,
      "loss": 0.2262,
      "step": 106000
    },
    {
      "epoch": 163.59447004608296,
      "grad_norm": 0.32526126503944397,
      "learning_rate": 1.8216756341275942e-05,
      "loss": 0.2263,
      "step": 106500
    },
    {
      "epoch": 164.36251920122888,
      "grad_norm": 0.3747202754020691,
      "learning_rate": 1.7832436587240587e-05,
      "loss": 0.226,
      "step": 107000
    },
    {
      "epoch": 165.1305683563748,
      "grad_norm": 0.3458299934864044,
      "learning_rate": 1.7448116833205226e-05,
      "loss": 0.2258,
      "step": 107500
    },
    {
      "epoch": 165.89861751152074,
      "grad_norm": 0.38587328791618347,
      "learning_rate": 1.7063797079169872e-05,
      "loss": 0.2259,
      "step": 108000
    },
    {
      "epoch": 166.66666666666666,
      "grad_norm": 0.2517000138759613,
      "learning_rate": 1.6679477325134514e-05,
      "loss": 0.2258,
      "step": 108500
    },
    {
      "epoch": 167.4347158218126,
      "grad_norm": 0.20193368196487427,
      "learning_rate": 1.6295157571099156e-05,
      "loss": 0.2258,
      "step": 109000
    },
    {
      "epoch": 168.20276497695852,
      "grad_norm": 0.38332441449165344,
      "learning_rate": 1.5910837817063798e-05,
      "loss": 0.2257,
      "step": 109500
    },
    {
      "epoch": 168.97081413210446,
      "grad_norm": 0.3254782259464264,
      "learning_rate": 1.552651806302844e-05,
      "loss": 0.2257,
      "step": 110000
    },
    {
      "epoch": 169.73886328725038,
      "grad_norm": 0.41482630372047424,
      "learning_rate": 1.5142198308993082e-05,
      "loss": 0.2255,
      "step": 110500
    },
    {
      "epoch": 170.50691244239633,
      "grad_norm": 0.2650170624256134,
      "learning_rate": 1.4757878554957725e-05,
      "loss": 0.2257,
      "step": 111000
    },
    {
      "epoch": 171.27496159754224,
      "grad_norm": 0.4618697464466095,
      "learning_rate": 1.4373558800922368e-05,
      "loss": 0.2253,
      "step": 111500
    },
    {
      "epoch": 172.04301075268816,
      "grad_norm": 0.33187657594680786,
      "learning_rate": 1.3989239046887009e-05,
      "loss": 0.2255,
      "step": 112000
    },
    {
      "epoch": 172.8110599078341,
      "grad_norm": 0.1910208761692047,
      "learning_rate": 1.3604919292851653e-05,
      "loss": 0.2253,
      "step": 112500
    },
    {
      "epoch": 173.57910906298002,
      "grad_norm": 0.4083366096019745,
      "learning_rate": 1.3220599538816295e-05,
      "loss": 0.2253,
      "step": 113000
    },
    {
      "epoch": 174.34715821812597,
      "grad_norm": 0.2542661726474762,
      "learning_rate": 1.2836279784780939e-05,
      "loss": 0.2254,
      "step": 113500
    },
    {
      "epoch": 175.1152073732719,
      "grad_norm": 0.3891897201538086,
      "learning_rate": 1.2451960030745581e-05,
      "loss": 0.2253,
      "step": 114000
    },
    {
      "epoch": 175.88325652841783,
      "grad_norm": 0.3938438892364502,
      "learning_rate": 1.2067640276710223e-05,
      "loss": 0.2251,
      "step": 114500
    },
    {
      "epoch": 176.65130568356375,
      "grad_norm": 0.2877328097820282,
      "learning_rate": 1.1683320522674867e-05,
      "loss": 0.2251,
      "step": 115000
    },
    {
      "epoch": 177.41935483870967,
      "grad_norm": 0.31713128089904785,
      "learning_rate": 1.1299000768639509e-05,
      "loss": 0.225,
      "step": 115500
    },
    {
      "epoch": 178.1874039938556,
      "grad_norm": 0.24118682742118835,
      "learning_rate": 1.0914681014604151e-05,
      "loss": 0.2254,
      "step": 116000
    },
    {
      "epoch": 178.95545314900153,
      "grad_norm": 0.4135581851005554,
      "learning_rate": 1.0530361260568793e-05,
      "loss": 0.2248,
      "step": 116500
    },
    {
      "epoch": 179.72350230414747,
      "grad_norm": 0.2900885343551636,
      "learning_rate": 1.0146041506533437e-05,
      "loss": 0.2252,
      "step": 117000
    },
    {
      "epoch": 180.4915514592934,
      "grad_norm": 0.381908655166626,
      "learning_rate": 9.76172175249808e-06,
      "loss": 0.2246,
      "step": 117500
    },
    {
      "epoch": 181.25960061443934,
      "grad_norm": 0.3722780644893646,
      "learning_rate": 9.377401998462721e-06,
      "loss": 0.225,
      "step": 118000
    },
    {
      "epoch": 182.02764976958525,
      "grad_norm": 0.5298388600349426,
      "learning_rate": 8.993082244427364e-06,
      "loss": 0.225,
      "step": 118500
    },
    {
      "epoch": 182.79569892473117,
      "grad_norm": 0.2196751832962036,
      "learning_rate": 8.608762490392007e-06,
      "loss": 0.2249,
      "step": 119000
    },
    {
      "epoch": 183.56374807987712,
      "grad_norm": 0.2808617055416107,
      "learning_rate": 8.22444273635665e-06,
      "loss": 0.2249,
      "step": 119500
    },
    {
      "epoch": 184.33179723502303,
      "grad_norm": 0.3356925845146179,
      "learning_rate": 7.840122982321292e-06,
      "loss": 0.2251,
      "step": 120000
    },
    {
      "epoch": 185.09984639016898,
      "grad_norm": 0.5323334336280823,
      "learning_rate": 7.455803228285935e-06,
      "loss": 0.2242,
      "step": 120500
    },
    {
      "epoch": 185.8678955453149,
      "grad_norm": 0.38467854261398315,
      "learning_rate": 7.071483474250577e-06,
      "loss": 0.2248,
      "step": 121000
    },
    {
      "epoch": 186.63594470046084,
      "grad_norm": 0.24243485927581787,
      "learning_rate": 6.68716372021522e-06,
      "loss": 0.2243,
      "step": 121500
    },
    {
      "epoch": 187.40399385560676,
      "grad_norm": 0.2818349599838257,
      "learning_rate": 6.302843966179863e-06,
      "loss": 0.2255,
      "step": 122000
    },
    {
      "epoch": 188.1720430107527,
      "grad_norm": 0.30189961194992065,
      "learning_rate": 5.918524212144504e-06,
      "loss": 0.2246,
      "step": 122500
    },
    {
      "epoch": 188.94009216589862,
      "grad_norm": 0.3766460716724396,
      "learning_rate": 5.534204458109147e-06,
      "loss": 0.2245,
      "step": 123000
    },
    {
      "epoch": 189.70814132104454,
      "grad_norm": 0.3848859667778015,
      "learning_rate": 5.149884704073789e-06,
      "loss": 0.2249,
      "step": 123500
    },
    {
      "epoch": 190.47619047619048,
      "grad_norm": 0.22628764808177948,
      "learning_rate": 4.765564950038432e-06,
      "loss": 0.2247,
      "step": 124000
    },
    {
      "epoch": 191.2442396313364,
      "grad_norm": 0.3465723693370819,
      "learning_rate": 4.3812451960030744e-06,
      "loss": 0.2245,
      "step": 124500
    },
    {
      "epoch": 192.01228878648234,
      "grad_norm": 0.3666357100009918,
      "learning_rate": 3.9969254419677174e-06,
      "loss": 0.2244,
      "step": 125000
    },
    {
      "epoch": 192.78033794162826,
      "grad_norm": 0.5335347056388855,
      "learning_rate": 3.61260568793236e-06,
      "loss": 0.2246,
      "step": 125500
    },
    {
      "epoch": 193.5483870967742,
      "grad_norm": 0.2268662452697754,
      "learning_rate": 3.2282859338970026e-06,
      "loss": 0.2245,
      "step": 126000
    },
    {
      "epoch": 194.31643625192012,
      "grad_norm": 0.3421744406223297,
      "learning_rate": 2.843966179861645e-06,
      "loss": 0.2243,
      "step": 126500
    },
    {
      "epoch": 195.08448540706604,
      "grad_norm": 0.258118212223053,
      "learning_rate": 2.4596464258262877e-06,
      "loss": 0.2248,
      "step": 127000
    },
    {
      "epoch": 195.85253456221199,
      "grad_norm": 0.3658291697502136,
      "learning_rate": 2.0753266717909303e-06,
      "loss": 0.2244,
      "step": 127500
    },
    {
      "epoch": 196.6205837173579,
      "grad_norm": 0.35651895403862,
      "learning_rate": 1.6910069177555729e-06,
      "loss": 0.2248,
      "step": 128000
    },
    {
      "epoch": 197.38863287250385,
      "grad_norm": 0.29317161440849304,
      "learning_rate": 1.3066871637202154e-06,
      "loss": 0.2241,
      "step": 128500
    },
    {
      "epoch": 198.15668202764977,
      "grad_norm": 0.286078542470932,
      "learning_rate": 9.223674096848578e-07,
      "loss": 0.2247,
      "step": 129000
    },
    {
      "epoch": 198.9247311827957,
      "grad_norm": 0.42530500888824463,
      "learning_rate": 5.380476556495005e-07,
      "loss": 0.2247,
      "step": 129500
    },
    {
      "epoch": 199.69278033794163,
      "grad_norm": 0.31158187985420227,
      "learning_rate": 1.5372790161414298e-07,
      "loss": 0.2243,
      "step": 130000
    },
    {
      "epoch": 200.46082949308754,
      "grad_norm": 0.4674430787563324,
      "learning_rate": 3.319672131147541e-05,
      "loss": 0.2249,
      "step": 130500
    },
    {
      "epoch": 201.2288786482335,
      "grad_norm": 0.37485313415527344,
      "learning_rate": 3.2940573770491805e-05,
      "loss": 0.2247,
      "step": 131000
    },
    {
      "epoch": 201.9969278033794,
      "grad_norm": 0.27974197268486023,
      "learning_rate": 3.26844262295082e-05,
      "loss": 0.2243,
      "step": 131500
    },
    {
      "epoch": 202.76497695852535,
      "grad_norm": 0.46727174520492554,
      "learning_rate": 3.242827868852459e-05,
      "loss": 0.2246,
      "step": 132000
    },
    {
      "epoch": 203.53302611367127,
      "grad_norm": 0.31026822328567505,
      "learning_rate": 3.2172131147540984e-05,
      "loss": 0.2242,
      "step": 132500
    },
    {
      "epoch": 204.30107526881721,
      "grad_norm": 0.46535027027130127,
      "learning_rate": 3.191598360655738e-05,
      "loss": 0.224,
      "step": 133000
    },
    {
      "epoch": 205.06912442396313,
      "grad_norm": 0.5581427812576294,
      "learning_rate": 3.165983606557377e-05,
      "loss": 0.2243,
      "step": 133500
    },
    {
      "epoch": 205.83717357910908,
      "grad_norm": 0.4684785306453705,
      "learning_rate": 3.1403688524590163e-05,
      "loss": 0.2241,
      "step": 134000
    },
    {
      "epoch": 206.605222734255,
      "grad_norm": 0.3585561215877533,
      "learning_rate": 3.114754098360656e-05,
      "loss": 0.2239,
      "step": 134500
    },
    {
      "epoch": 207.3732718894009,
      "grad_norm": 0.327210932970047,
      "learning_rate": 3.089139344262295e-05,
      "loss": 0.2239,
      "step": 135000
    },
    {
      "epoch": 208.14132104454686,
      "grad_norm": 0.4360223114490509,
      "learning_rate": 3.063524590163935e-05,
      "loss": 0.2237,
      "step": 135500
    },
    {
      "epoch": 208.90937019969277,
      "grad_norm": 0.38154128193855286,
      "learning_rate": 3.037909836065574e-05,
      "loss": 0.2237,
      "step": 136000
    },
    {
      "epoch": 209.67741935483872,
      "grad_norm": 0.21252308785915375,
      "learning_rate": 3.012295081967213e-05,
      "loss": 0.2235,
      "step": 136500
    },
    {
      "epoch": 210.44546850998464,
      "grad_norm": 0.32806918025016785,
      "learning_rate": 2.9866803278688525e-05,
      "loss": 0.2233,
      "step": 137000
    },
    {
      "epoch": 211.21351766513058,
      "grad_norm": 0.3739381730556488,
      "learning_rate": 2.961065573770492e-05,
      "loss": 0.2238,
      "step": 137500
    },
    {
      "epoch": 211.9815668202765,
      "grad_norm": 0.4887678027153015,
      "learning_rate": 2.9354508196721315e-05,
      "loss": 0.2233,
      "step": 138000
    },
    {
      "epoch": 212.74961597542242,
      "grad_norm": 0.3299216032028198,
      "learning_rate": 2.9098360655737705e-05,
      "loss": 0.223,
      "step": 138500
    },
    {
      "epoch": 213.51766513056836,
      "grad_norm": 0.4028381109237671,
      "learning_rate": 2.88422131147541e-05,
      "loss": 0.2232,
      "step": 139000
    },
    {
      "epoch": 214.28571428571428,
      "grad_norm": 0.35866501927375793,
      "learning_rate": 2.8586065573770494e-05,
      "loss": 0.2232,
      "step": 139500
    },
    {
      "epoch": 215.05376344086022,
      "grad_norm": 0.302934467792511,
      "learning_rate": 2.8329918032786884e-05,
      "loss": 0.2231,
      "step": 140000
    },
    {
      "epoch": 215.82181259600614,
      "grad_norm": 0.3436555862426758,
      "learning_rate": 2.807377049180328e-05,
      "loss": 0.2228,
      "step": 140500
    },
    {
      "epoch": 216.58986175115209,
      "grad_norm": 0.28662586212158203,
      "learning_rate": 2.781762295081967e-05,
      "loss": 0.223,
      "step": 141000
    },
    {
      "epoch": 217.357910906298,
      "grad_norm": 0.36882027983665466,
      "learning_rate": 2.7561475409836067e-05,
      "loss": 0.2228,
      "step": 141500
    },
    {
      "epoch": 218.12596006144392,
      "grad_norm": 0.2712598145008087,
      "learning_rate": 2.730532786885246e-05,
      "loss": 0.2228,
      "step": 142000
    },
    {
      "epoch": 218.89400921658986,
      "grad_norm": 0.3808492422103882,
      "learning_rate": 2.7049180327868856e-05,
      "loss": 0.2226,
      "step": 142500
    },
    {
      "epoch": 219.66205837173578,
      "grad_norm": 0.6566872000694275,
      "learning_rate": 2.6793032786885246e-05,
      "loss": 0.2223,
      "step": 143000
    },
    {
      "epoch": 220.43010752688173,
      "grad_norm": 0.2535436153411865,
      "learning_rate": 2.653688524590164e-05,
      "loss": 0.2226,
      "step": 143500
    },
    {
      "epoch": 221.19815668202764,
      "grad_norm": 0.25390225648880005,
      "learning_rate": 2.6280737704918036e-05,
      "loss": 0.2226,
      "step": 144000
    },
    {
      "epoch": 221.9662058371736,
      "grad_norm": 0.4159427583217621,
      "learning_rate": 2.6024590163934425e-05,
      "loss": 0.2223,
      "step": 144500
    },
    {
      "epoch": 222.7342549923195,
      "grad_norm": 0.5988849997520447,
      "learning_rate": 2.5768442622950822e-05,
      "loss": 0.2223,
      "step": 145000
    },
    {
      "epoch": 223.50230414746545,
      "grad_norm": 0.2807886600494385,
      "learning_rate": 2.5512295081967215e-05,
      "loss": 0.2225,
      "step": 145500
    },
    {
      "epoch": 224.27035330261137,
      "grad_norm": 0.3029777705669403,
      "learning_rate": 2.525614754098361e-05,
      "loss": 0.222,
      "step": 146000
    },
    {
      "epoch": 225.0384024577573,
      "grad_norm": 0.39887917041778564,
      "learning_rate": 2.5e-05,
      "loss": 0.2222,
      "step": 146500
    },
    {
      "epoch": 225.80645161290323,
      "grad_norm": 0.5863353610038757,
      "learning_rate": 2.4743852459016394e-05,
      "loss": 0.2221,
      "step": 147000
    },
    {
      "epoch": 226.57450076804915,
      "grad_norm": 0.5375610589981079,
      "learning_rate": 2.4487704918032787e-05,
      "loss": 0.2219,
      "step": 147500
    },
    {
      "epoch": 227.3425499231951,
      "grad_norm": 0.36376050114631653,
      "learning_rate": 2.4231557377049184e-05,
      "loss": 0.2217,
      "step": 148000
    },
    {
      "epoch": 228.110599078341,
      "grad_norm": 0.24497903883457184,
      "learning_rate": 2.3975409836065574e-05,
      "loss": 0.2221,
      "step": 148500
    },
    {
      "epoch": 228.87864823348696,
      "grad_norm": 0.4601845443248749,
      "learning_rate": 2.3719262295081967e-05,
      "loss": 0.2219,
      "step": 149000
    },
    {
      "epoch": 229.64669738863287,
      "grad_norm": 0.6162793040275574,
      "learning_rate": 2.346311475409836e-05,
      "loss": 0.222,
      "step": 149500
    },
    {
      "epoch": 230.4147465437788,
      "grad_norm": 0.45836278796195984,
      "learning_rate": 2.3206967213114756e-05,
      "loss": 0.2215,
      "step": 150000
    },
    {
      "epoch": 231.18279569892474,
      "grad_norm": 0.4774148762226105,
      "learning_rate": 2.295081967213115e-05,
      "loss": 0.2217,
      "step": 150500
    },
    {
      "epoch": 231.95084485407065,
      "grad_norm": 0.1622810661792755,
      "learning_rate": 2.2694672131147543e-05,
      "loss": 0.2216,
      "step": 151000
    },
    {
      "epoch": 232.7188940092166,
      "grad_norm": 0.5463170409202576,
      "learning_rate": 2.2438524590163936e-05,
      "loss": 0.2214,
      "step": 151500
    },
    {
      "epoch": 233.48694316436251,
      "grad_norm": 0.4790489971637726,
      "learning_rate": 2.218237704918033e-05,
      "loss": 0.2216,
      "step": 152000
    },
    {
      "epoch": 234.25499231950846,
      "grad_norm": 0.4222610890865326,
      "learning_rate": 2.1926229508196722e-05,
      "loss": 0.2212,
      "step": 152500
    },
    {
      "epoch": 235.02304147465438,
      "grad_norm": 0.42490360140800476,
      "learning_rate": 2.1670081967213115e-05,
      "loss": 0.2215,
      "step": 153000
    },
    {
      "epoch": 235.7910906298003,
      "grad_norm": 0.22499224543571472,
      "learning_rate": 2.1413934426229508e-05,
      "loss": 0.2213,
      "step": 153500
    },
    {
      "epoch": 236.55913978494624,
      "grad_norm": 0.3580728769302368,
      "learning_rate": 2.1157786885245905e-05,
      "loss": 0.2212,
      "step": 154000
    },
    {
      "epoch": 237.32718894009216,
      "grad_norm": 0.254155695438385,
      "learning_rate": 2.0901639344262298e-05,
      "loss": 0.2212,
      "step": 154500
    },
    {
      "epoch": 238.0952380952381,
      "grad_norm": 0.3666870594024658,
      "learning_rate": 2.0645491803278687e-05,
      "loss": 0.2211,
      "step": 155000
    },
    {
      "epoch": 238.86328725038402,
      "grad_norm": 0.4124234914779663,
      "learning_rate": 2.038934426229508e-05,
      "loss": 0.221,
      "step": 155500
    },
    {
      "epoch": 239.63133640552996,
      "grad_norm": 0.3872339427471161,
      "learning_rate": 2.0133196721311477e-05,
      "loss": 0.2215,
      "step": 156000
    },
    {
      "epoch": 240.39938556067588,
      "grad_norm": 0.35500890016555786,
      "learning_rate": 1.987704918032787e-05,
      "loss": 0.2203,
      "step": 156500
    },
    {
      "epoch": 241.16743471582183,
      "grad_norm": 0.4313068687915802,
      "learning_rate": 1.9620901639344263e-05,
      "loss": 0.2214,
      "step": 157000
    },
    {
      "epoch": 241.93548387096774,
      "grad_norm": 0.5325278639793396,
      "learning_rate": 1.9364754098360656e-05,
      "loss": 0.2208,
      "step": 157500
    },
    {
      "epoch": 242.70353302611366,
      "grad_norm": 0.47386446595191956,
      "learning_rate": 1.9108606557377053e-05,
      "loss": 0.2208,
      "step": 158000
    },
    {
      "epoch": 243.4715821812596,
      "grad_norm": 0.3387553095817566,
      "learning_rate": 1.8852459016393442e-05,
      "loss": 0.2209,
      "step": 158500
    },
    {
      "epoch": 244.23963133640552,
      "grad_norm": 0.4460451602935791,
      "learning_rate": 1.8596311475409836e-05,
      "loss": 0.2206,
      "step": 159000
    },
    {
      "epoch": 245.00768049155147,
      "grad_norm": 0.3345969617366791,
      "learning_rate": 1.834016393442623e-05,
      "loss": 0.2207,
      "step": 159500
    },
    {
      "epoch": 245.77572964669739,
      "grad_norm": 0.43684259057044983,
      "learning_rate": 1.8084016393442625e-05,
      "loss": 0.2208,
      "step": 160000
    },
    {
      "epoch": 246.54377880184333,
      "grad_norm": 0.49693000316619873,
      "learning_rate": 1.7827868852459018e-05,
      "loss": 0.2203,
      "step": 160500
    },
    {
      "epoch": 247.31182795698925,
      "grad_norm": 0.4386803209781647,
      "learning_rate": 1.757172131147541e-05,
      "loss": 0.2206,
      "step": 161000
    },
    {
      "epoch": 248.07987711213516,
      "grad_norm": 0.5204593539237976,
      "learning_rate": 1.7315573770491804e-05,
      "loss": 0.2205,
      "step": 161500
    },
    {
      "epoch": 248.8479262672811,
      "grad_norm": 0.29547736048698425,
      "learning_rate": 1.7059426229508198e-05,
      "loss": 0.2208,
      "step": 162000
    },
    {
      "epoch": 249.61597542242703,
      "grad_norm": 0.24777968227863312,
      "learning_rate": 1.680327868852459e-05,
      "loss": 0.2205,
      "step": 162500
    },
    {
      "epoch": 250.38402457757297,
      "grad_norm": 0.4148571193218231,
      "learning_rate": 1.6547131147540984e-05,
      "loss": 0.22,
      "step": 163000
    },
    {
      "epoch": 251.1520737327189,
      "grad_norm": 0.5142343640327454,
      "learning_rate": 1.6290983606557377e-05,
      "loss": 0.2204,
      "step": 163500
    },
    {
      "epoch": 251.92012288786484,
      "grad_norm": 0.29054906964302063,
      "learning_rate": 1.6034836065573773e-05,
      "loss": 0.2202,
      "step": 164000
    },
    {
      "epoch": 252.68817204301075,
      "grad_norm": 0.3084721565246582,
      "learning_rate": 1.5778688524590166e-05,
      "loss": 0.2205,
      "step": 164500
    },
    {
      "epoch": 253.45622119815667,
      "grad_norm": 0.28685012459754944,
      "learning_rate": 1.552254098360656e-05,
      "loss": 0.2204,
      "step": 165000
    },
    {
      "epoch": 254.22427035330261,
      "grad_norm": 0.5448203682899475,
      "learning_rate": 1.526639344262295e-05,
      "loss": 0.2201,
      "step": 165500
    },
    {
      "epoch": 254.99231950844853,
      "grad_norm": 0.3662637174129486,
      "learning_rate": 1.5010245901639344e-05,
      "loss": 0.2201,
      "step": 166000
    },
    {
      "epoch": 255.76036866359448,
      "grad_norm": 0.33909711241722107,
      "learning_rate": 1.4754098360655739e-05,
      "loss": 0.22,
      "step": 166500
    },
    {
      "epoch": 256.5284178187404,
      "grad_norm": 0.5218294858932495,
      "learning_rate": 1.4497950819672132e-05,
      "loss": 0.2202,
      "step": 167000
    },
    {
      "epoch": 257.2964669738863,
      "grad_norm": 0.5846849679946899,
      "learning_rate": 1.4241803278688525e-05,
      "loss": 0.2201,
      "step": 167500
    },
    {
      "epoch": 258.06451612903226,
      "grad_norm": 0.23994767665863037,
      "learning_rate": 1.398565573770492e-05,
      "loss": 0.2199,
      "step": 168000
    },
    {
      "epoch": 258.8325652841782,
      "grad_norm": 0.28590717911720276,
      "learning_rate": 1.3729508196721313e-05,
      "loss": 0.2202,
      "step": 168500
    },
    {
      "epoch": 259.6006144393241,
      "grad_norm": 0.5076656341552734,
      "learning_rate": 1.3473360655737704e-05,
      "loss": 0.2199,
      "step": 169000
    },
    {
      "epoch": 260.36866359447004,
      "grad_norm": 0.19853349030017853,
      "learning_rate": 1.32172131147541e-05,
      "loss": 0.22,
      "step": 169500
    },
    {
      "epoch": 261.136712749616,
      "grad_norm": 0.4094199538230896,
      "learning_rate": 1.2961065573770492e-05,
      "loss": 0.2199,
      "step": 170000
    },
    {
      "epoch": 261.9047619047619,
      "grad_norm": 0.40454402565956116,
      "learning_rate": 1.2704918032786885e-05,
      "loss": 0.2198,
      "step": 170500
    },
    {
      "epoch": 262.6728110599078,
      "grad_norm": 0.3571152091026306,
      "learning_rate": 1.244877049180328e-05,
      "loss": 0.2198,
      "step": 171000
    },
    {
      "epoch": 263.44086021505376,
      "grad_norm": 0.2980431914329529,
      "learning_rate": 1.2192622950819672e-05,
      "loss": 0.2198,
      "step": 171500
    },
    {
      "epoch": 264.2089093701997,
      "grad_norm": 0.19754362106323242,
      "learning_rate": 1.1936475409836066e-05,
      "loss": 0.22,
      "step": 172000
    },
    {
      "epoch": 264.9769585253456,
      "grad_norm": 0.21679151058197021,
      "learning_rate": 1.168032786885246e-05,
      "loss": 0.2195,
      "step": 172500
    },
    {
      "epoch": 265.74500768049154,
      "grad_norm": 0.4683558940887451,
      "learning_rate": 1.1424180327868853e-05,
      "loss": 0.2198,
      "step": 173000
    },
    {
      "epoch": 266.5130568356375,
      "grad_norm": 0.32840991020202637,
      "learning_rate": 1.1168032786885246e-05,
      "loss": 0.2198,
      "step": 173500
    },
    {
      "epoch": 267.28110599078343,
      "grad_norm": 0.5717460513114929,
      "learning_rate": 1.091188524590164e-05,
      "loss": 0.2194,
      "step": 174000
    },
    {
      "epoch": 268.0491551459293,
      "grad_norm": 0.3008240759372711,
      "learning_rate": 1.0655737704918032e-05,
      "loss": 0.2197,
      "step": 174500
    },
    {
      "epoch": 268.81720430107526,
      "grad_norm": 0.3636632263660431,
      "learning_rate": 1.0399590163934427e-05,
      "loss": 0.2197,
      "step": 175000
    },
    {
      "epoch": 269.5852534562212,
      "grad_norm": 0.3924686908721924,
      "learning_rate": 1.014344262295082e-05,
      "loss": 0.2192,
      "step": 175500
    },
    {
      "epoch": 270.35330261136716,
      "grad_norm": 0.24817830324172974,
      "learning_rate": 9.887295081967215e-06,
      "loss": 0.2201,
      "step": 176000
    },
    {
      "epoch": 271.12135176651304,
      "grad_norm": 0.46540728211402893,
      "learning_rate": 9.631147540983606e-06,
      "loss": 0.2194,
      "step": 176500
    },
    {
      "epoch": 271.889400921659,
      "grad_norm": 0.29778051376342773,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.2197,
      "step": 177000
    },
    {
      "epoch": 272.65745007680493,
      "grad_norm": 0.5645861029624939,
      "learning_rate": 9.118852459016394e-06,
      "loss": 0.2195,
      "step": 177500
    },
    {
      "epoch": 273.4254992319508,
      "grad_norm": 0.4353109896183014,
      "learning_rate": 8.862704918032787e-06,
      "loss": 0.2195,
      "step": 178000
    },
    {
      "epoch": 274.19354838709677,
      "grad_norm": 0.5745933651924133,
      "learning_rate": 8.60655737704918e-06,
      "loss": 0.2194,
      "step": 178500
    },
    {
      "epoch": 274.9615975422427,
      "grad_norm": 0.2944279909133911,
      "learning_rate": 8.350409836065575e-06,
      "loss": 0.2194,
      "step": 179000
    },
    {
      "epoch": 275.72964669738866,
      "grad_norm": 0.3398967683315277,
      "learning_rate": 8.094262295081968e-06,
      "loss": 0.2194,
      "step": 179500
    },
    {
      "epoch": 276.49769585253455,
      "grad_norm": 0.3541880249977112,
      "learning_rate": 7.838114754098361e-06,
      "loss": 0.2196,
      "step": 180000
    },
    {
      "epoch": 277.2657450076805,
      "grad_norm": 0.3077373504638672,
      "learning_rate": 7.581967213114754e-06,
      "loss": 0.219,
      "step": 180500
    },
    {
      "epoch": 278.03379416282644,
      "grad_norm": 0.3010064363479614,
      "learning_rate": 7.325819672131148e-06,
      "loss": 0.2196,
      "step": 181000
    },
    {
      "epoch": 278.8018433179723,
      "grad_norm": 0.26102277636528015,
      "learning_rate": 7.0696721311475405e-06,
      "loss": 0.2193,
      "step": 181500
    },
    {
      "epoch": 279.5698924731183,
      "grad_norm": 0.37562406063079834,
      "learning_rate": 6.8135245901639345e-06,
      "loss": 0.2192,
      "step": 182000
    },
    {
      "epoch": 280.3379416282642,
      "grad_norm": 0.2854296565055847,
      "learning_rate": 6.557377049180328e-06,
      "loss": 0.2195,
      "step": 182500
    },
    {
      "epoch": 281.10599078341016,
      "grad_norm": 0.41208329796791077,
      "learning_rate": 6.301229508196721e-06,
      "loss": 0.219,
      "step": 183000
    },
    {
      "epoch": 281.87403993855605,
      "grad_norm": 0.4124978184700012,
      "learning_rate": 6.045081967213115e-06,
      "loss": 0.2195,
      "step": 183500
    },
    {
      "epoch": 282.642089093702,
      "grad_norm": 0.30963653326034546,
      "learning_rate": 5.7889344262295086e-06,
      "loss": 0.2193,
      "step": 184000
    },
    {
      "epoch": 283.41013824884794,
      "grad_norm": 0.34853678941726685,
      "learning_rate": 5.532786885245902e-06,
      "loss": 0.2188,
      "step": 184500
    },
    {
      "epoch": 284.17818740399383,
      "grad_norm": 0.34705817699432373,
      "learning_rate": 5.276639344262296e-06,
      "loss": 0.2195,
      "step": 185000
    },
    {
      "epoch": 284.9462365591398,
      "grad_norm": 0.3763677179813385,
      "learning_rate": 5.020491803278689e-06,
      "loss": 0.2191,
      "step": 185500
    },
    {
      "epoch": 285.7142857142857,
      "grad_norm": 0.38650989532470703,
      "learning_rate": 4.764344262295082e-06,
      "loss": 0.2193,
      "step": 186000
    },
    {
      "epoch": 286.48233486943167,
      "grad_norm": 0.2954444885253906,
      "learning_rate": 4.508196721311476e-06,
      "loss": 0.2192,
      "step": 186500
    },
    {
      "epoch": 287.25038402457756,
      "grad_norm": 0.2598889470100403,
      "learning_rate": 4.252049180327869e-06,
      "loss": 0.219,
      "step": 187000
    },
    {
      "epoch": 288.0184331797235,
      "grad_norm": 0.28875985741615295,
      "learning_rate": 3.995901639344263e-06,
      "loss": 0.2194,
      "step": 187500
    },
    {
      "epoch": 288.78648233486945,
      "grad_norm": 0.47326982021331787,
      "learning_rate": 3.739754098360656e-06,
      "loss": 0.2191,
      "step": 188000
    },
    {
      "epoch": 289.55453149001534,
      "grad_norm": 0.226674884557724,
      "learning_rate": 3.483606557377049e-06,
      "loss": 0.219,
      "step": 188500
    },
    {
      "epoch": 290.3225806451613,
      "grad_norm": 0.3793441653251648,
      "learning_rate": 3.227459016393443e-06,
      "loss": 0.2193,
      "step": 189000
    },
    {
      "epoch": 291.0906298003072,
      "grad_norm": 0.45140379667282104,
      "learning_rate": 2.971311475409836e-06,
      "loss": 0.219,
      "step": 189500
    },
    {
      "epoch": 291.8586789554532,
      "grad_norm": 0.3420637547969818,
      "learning_rate": 2.7151639344262296e-06,
      "loss": 0.2192,
      "step": 190000
    },
    {
      "epoch": 292.62672811059906,
      "grad_norm": 0.30274680256843567,
      "learning_rate": 2.459016393442623e-06,
      "loss": 0.2189,
      "step": 190500
    },
    {
      "epoch": 293.394777265745,
      "grad_norm": 0.4614971876144409,
      "learning_rate": 2.2028688524590167e-06,
      "loss": 0.2194,
      "step": 191000
    },
    {
      "epoch": 294.16282642089095,
      "grad_norm": 0.3201971650123596,
      "learning_rate": 1.94672131147541e-06,
      "loss": 0.2192,
      "step": 191500
    },
    {
      "epoch": 294.93087557603684,
      "grad_norm": 0.5175557732582092,
      "learning_rate": 1.6905737704918035e-06,
      "loss": 0.2189,
      "step": 192000
    },
    {
      "epoch": 295.6989247311828,
      "grad_norm": 0.5007583498954773,
      "learning_rate": 1.4344262295081968e-06,
      "loss": 0.219,
      "step": 192500
    },
    {
      "epoch": 296.46697388632873,
      "grad_norm": 0.3394189774990082,
      "learning_rate": 1.1782786885245902e-06,
      "loss": 0.2192,
      "step": 193000
    },
    {
      "epoch": 297.2350230414747,
      "grad_norm": 0.2568089962005615,
      "learning_rate": 9.221311475409837e-07,
      "loss": 0.2189,
      "step": 193500
    },
    {
      "epoch": 298.00307219662056,
      "grad_norm": 0.2755890488624573,
      "learning_rate": 6.65983606557377e-07,
      "loss": 0.2192,
      "step": 194000
    },
    {
      "epoch": 298.7711213517665,
      "grad_norm": 0.363180011510849,
      "learning_rate": 4.098360655737705e-07,
      "loss": 0.2191,
      "step": 194500
    },
    {
      "epoch": 299.53917050691246,
      "grad_norm": 0.33109238743782043,
      "learning_rate": 1.5368852459016395e-07,
      "loss": 0.2188,
      "step": 195000
    }
  ],
  "logging_steps": 500,
  "max_steps": 195300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 300,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1024,
  "trial_name": null,
  "trial_params": null
}
